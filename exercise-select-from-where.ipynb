{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [SQL](https://www.kaggle.com/learn/intro-to-sql) course.  You can reference the tutorial at [this link](https://www.kaggle.com/dansbecker/select-from-where).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nTry writing some **SELECT** statements of your own to explore a large dataset of air pollution measurements.\n\nRun the cell below to set up the feedback system.","metadata":{}},{"cell_type":"code","source":"# Set up feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.sql.ex2 import *\nprint(\"Setup Complete\")","metadata":{"execution":{"iopub.status.busy":"2022-03-10T11:50:48.316791Z","iopub.execute_input":"2022-03-10T11:50:48.317463Z","iopub.status.idle":"2022-03-10T11:50:50.670073Z","shell.execute_reply.started":"2022-03-10T11:50:48.317324Z","shell.execute_reply":"2022-03-10T11:50:50.669370Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"The code cell below fetches the `global_air_quality` table from the `openaq` dataset.  We also preview the first five rows of the table.","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\n\n# Create a \"Client\" object\nclient = bigquery.Client()\n\n# Construct a reference to the \"openaq\" dataset\ndataset_ref = client.dataset(\"openaq\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)\n\n# Construct a reference to the \"global_air_quality\" table\ntable_ref = dataset_ref.table(\"global_air_quality\")\n\n# API request - fetch the table\ntable = client.get_table(table_ref)\n\n# Preview the first five lines of the \"global_air_quality\" table\nclient.list_rows(table, max_results=5).to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T11:50:50.671315Z","iopub.execute_input":"2022-03-10T11:50:50.671652Z","iopub.status.idle":"2022-03-10T11:50:51.535969Z","shell.execute_reply.started":"2022-03-10T11:50:50.671624Z","shell.execute_reply":"2022-03-10T11:50:51.535005Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Exercises\n\n### 1) Units of measurement\n\nWhich countries have reported pollution levels in units of \"ppm\"?  In the code cell below, set `first_query` to an SQL query that pulls the appropriate entries from the `country` column.\n\nIn case it's useful to see an example query, here's some code from the tutorial:\n\n```\nquery = \"\"\"\n        SELECT city\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE country = 'US'\n        \"\"\"\n```","metadata":{}},{"cell_type":"code","source":"# Query to select countries with units of \"ppm\"\nfirst_query = \"\"\"\n              SELECT DISTINCT country\n              FROM `bigquery-public-data.openaq.global_air_quality`\n              WHERE unit = 'ppm'\n              \"\"\" # Your code goes here\n\n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 10 GB)\n#safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n#first_query_job = client.query(first_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nfirst_results = first_query_job.to_dataframe()\n\n# View top few rows of results\nprint(first_results.head())\n\n# Check your answer\nq_1.check()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T11:54:38.382447Z","iopub.execute_input":"2022-03-10T11:54:38.382757Z","iopub.status.idle":"2022-03-10T11:54:38.715748Z","shell.execute_reply.started":"2022-03-10T11:54:38.382724Z","shell.execute_reply":"2022-03-10T11:54:38.714511Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"For the solution, uncomment the line below.","metadata":{}},{"cell_type":"code","source":"q_1.solution()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T11:53:56.098832Z","iopub.execute_input":"2022-03-10T11:53:56.099120Z","iopub.status.idle":"2022-03-10T11:53:56.107233Z","shell.execute_reply.started":"2022-03-10T11:53:56.099090Z","shell.execute_reply":"2022-03-10T11:53:56.106392Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### 2) High air quality\n\nWhich pollution levels were reported to be exactly 0?  \n- Set `zero_pollution_query` to select **all columns** of the rows where the `value` column is 0.\n- Set `zero_pollution_results` to a pandas DataFrame containing the query results.","metadata":{}},{"cell_type":"code","source":"# Query to select all columns where pollution levels are exactly 0\nzero_pollution_query = \"\"\"\n                       SELECT *\n                       FROM `bigquery-public-data.openaq.global_air_quality`\n                       WHERE value = 0\n                       \"\"\" \n\n# Set up the query\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)   #isso aqui é algo pra não ultrapassar um valor ai \n\n#isso aqui é o que faz a query rodar!\nquery_job = client.query(zero_pollution_query, job_config=safe_config)\n\n# API request - run the query and return a pandas DataFrame\nzero_pollution_results = query_job.to_dataframe()\n\nprint(zero_pollution_results.head())\n\n# Check your answer\nq_2.check()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T11:59:27.566499Z","iopub.execute_input":"2022-03-10T11:59:27.566790Z","iopub.status.idle":"2022-03-10T11:59:28.628103Z","shell.execute_reply.started":"2022-03-10T11:59:27.566758Z","shell.execute_reply":"2022-03-10T11:59:28.627241Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"For the solution, uncomment the line below.","metadata":{}},{"cell_type":"code","source":"#q_2.solution()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T12:00:43.535454Z","iopub.execute_input":"2022-03-10T12:00:43.535718Z","iopub.status.idle":"2022-03-10T12:00:43.540323Z","shell.execute_reply.started":"2022-03-10T12:00:43.535692Z","shell.execute_reply":"2022-03-10T12:00:43.539261Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"That query wasn't too complicated, and it got the data you want. But these **SELECT** queries don't organizing data in a way that answers the most interesting questions. For that, we'll need the **GROUP BY** command. \n\nIf you know how to use [`groupby()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) in pandas, this is similar. But BigQuery works quickly with far larger datasets.\n\nFortunately, that's next.","metadata":{}},{"cell_type":"markdown","source":"# Keep going\n**[GROUP BY](https://www.kaggle.com/dansbecker/group-by-having-count)** clauses and their extensions give you the power to pull interesting statistics out of data, rather than receiving it in just its raw format.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-sql/discussion) to chat with other learners.*","metadata":{}}]}